{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('train_data.csv')\n",
    "test_dataset = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1204428 entries, 0 to 1204427\n",
      "Data columns (total 26 columns):\n",
      "addr_state             1204428 non-null object\n",
      "annual_inc             1204428 non-null float64\n",
      "issue_d                1204428 non-null object\n",
      "application_type       1204428 non-null object\n",
      "dti                    1204428 non-null float64\n",
      "emp_length             1204428 non-null object\n",
      "emp_title              1204428 non-null object\n",
      "funded_amnt            1204428 non-null float64\n",
      "funded_amnt_inv        1204428 non-null float64\n",
      "grade                  1204428 non-null object\n",
      "home_ownership         1204428 non-null object\n",
      "id                     1204428 non-null int64\n",
      "initial_list_status    1204428 non-null object\n",
      "loan_amnt              1204428 non-null float64\n",
      "member_id              1204428 non-null int64\n",
      "policy_code            1204428 non-null float64\n",
      "pub_rec                1204428 non-null float64\n",
      "purpose                1204428 non-null object\n",
      "sub_grade              1204428 non-null object\n",
      "term                   1204428 non-null object\n",
      "title                  1204428 non-null object\n",
      "total_acc              1204428 non-null float64\n",
      "total_pymnt            1204428 non-null float64\n",
      "zip_code               1204428 non-null object\n",
      "verification_status    1204428 non-null object\n",
      "default_ind            1204428 non-null int64\n",
      "dtypes: float64(9), int64(3), object(14)\n",
      "memory usage: 238.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246318 entries, 0 to 246317\n",
      "Data columns (total 26 columns):\n",
      "addr_state             246318 non-null object\n",
      "annual_inc             246318 non-null float64\n",
      "issue_d                246318 non-null object\n",
      "application_type       246318 non-null object\n",
      "dti                    246318 non-null float64\n",
      "emp_length             246318 non-null object\n",
      "emp_title              246318 non-null object\n",
      "funded_amnt            246318 non-null float64\n",
      "funded_amnt_inv        246318 non-null float64\n",
      "grade                  246318 non-null object\n",
      "home_ownership         246318 non-null object\n",
      "id                     246318 non-null int64\n",
      "initial_list_status    246318 non-null object\n",
      "loan_amnt              246318 non-null float64\n",
      "member_id              246318 non-null int64\n",
      "policy_code            246318 non-null float64\n",
      "pub_rec                246318 non-null float64\n",
      "purpose                246318 non-null object\n",
      "sub_grade              246318 non-null object\n",
      "term                   246318 non-null object\n",
      "title                  246318 non-null object\n",
      "total_acc              246318 non-null float64\n",
      "total_pymnt            246318 non-null float64\n",
      "zip_code               246318 non-null object\n",
      "verification_status    246318 non-null object\n",
      "default_ind            246318 non-null int64\n",
      "dtypes: float64(9), int64(3), object(14)\n",
      "memory usage: 48.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addr_state             0\n",
       "annual_inc             0\n",
       "issue_d                0\n",
       "application_type       0\n",
       "dti                    0\n",
       "emp_length             0\n",
       "emp_title              0\n",
       "funded_amnt            0\n",
       "funded_amnt_inv        0\n",
       "grade                  0\n",
       "home_ownership         0\n",
       "id                     0\n",
       "initial_list_status    0\n",
       "loan_amnt              0\n",
       "member_id              0\n",
       "policy_code            0\n",
       "pub_rec                0\n",
       "purpose                0\n",
       "sub_grade              0\n",
       "term                   0\n",
       "title                  0\n",
       "total_acc              0\n",
       "total_pymnt            0\n",
       "zip_code               0\n",
       "verification_status    0\n",
       "default_ind            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addr_state             0\n",
       "annual_inc             0\n",
       "issue_d                0\n",
       "application_type       0\n",
       "dti                    0\n",
       "emp_length             0\n",
       "emp_title              0\n",
       "funded_amnt            0\n",
       "funded_amnt_inv        0\n",
       "grade                  0\n",
       "home_ownership         0\n",
       "id                     0\n",
       "initial_list_status    0\n",
       "loan_amnt              0\n",
       "member_id              0\n",
       "policy_code            0\n",
       "pub_rec                0\n",
       "purpose                0\n",
       "sub_grade              0\n",
       "term                   0\n",
       "title                  0\n",
       "total_acc              0\n",
       "total_pymnt            0\n",
       "zip_code               0\n",
       "verification_status    0\n",
       "default_ind            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train_dataset, test_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr_state\n",
      "issue_d\n",
      "application_type\n",
      "emp_length\n",
      "emp_title\n",
      "grade\n",
      "home_ownership\n",
      "initial_list_status\n",
      "purpose\n",
      "sub_grade\n",
      "term\n",
      "title\n",
      "zip_code\n",
      "verification_status\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "category_colmap = {}\n",
    "for col in dataset.select_dtypes('object').columns:\n",
    "    print(col)\n",
    "    le_enc = LabelEncoder()\n",
    "    category_colmap[col] = le_enc\n",
    "    dataset[col] = le_enc.fit_transform(dataset[col])\n",
    "\n",
    "# ============== inverse transformation, getting true class name of labels ================ #\n",
    "#category_colmap['column_name'].inverse_transform([0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.iloc[0:len(train_dataset)].reset_index(drop=True)\n",
    "test_dataset = dataset.iloc[len(train_dataset):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_features = ['addr_state', 'annual_inc', 'issue_d', 'application_type', 'dti',\n",
    "       'emp_length', 'emp_title', 'funded_amnt', 'funded_amnt_inv', 'grade',\n",
    "       'home_ownership', 'id', 'initial_list_status', 'loan_amnt', 'member_id',\n",
    "       'policy_code', 'pub_rec', 'purpose', 'sub_grade', 'term', 'title',\n",
    "       'total_acc', 'total_pymnt', 'zip_code', 'verification_status']\n",
    "x = train_dataset[x_features]\n",
    "\n",
    "y_predictor = ['default_ind']\n",
    "y = train_dataset[y_predictor]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x,y,test_size=0.3)\n",
    "x_test, y_test = test_dataset[x_features], test_dataset[y_predictor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Class Distribution     # Count :{1: 477384, 0: 365715}, 0/1 Ratio :0.766, Class-0 % :0.434, Class-1 % :0.566\n",
      "Valiadity Data Class Distribution # Count :{1: 205192, 0: 156137}, 0/1 Ratio :0.761, Class-0 % :0.432, Class-1 % :0.568\n",
      "Test Data Class Distribution      # Count :{0: 241726, 1: 4592}, 0/1 Ratio :52.641, Class-0 % :0.981, Class-1 % :0.019\n"
     ]
    }
   ],
   "source": [
    "traindata_dist = dict(y_train['default_ind'].value_counts())\n",
    "validitydata_dist = dict(y_valid['default_ind'].value_counts())\n",
    "testdata_dist = dict(y_test['default_ind'].value_counts())\n",
    "\n",
    "print('Train Data Class Distribution     # Count :{}, 0/1 Ratio :{}, Class-0 % :{}, Class-1 % :{}'.format(traindata_dist, round((traindata_dist[0] / traindata_dist[1]),3), round((traindata_dist[0]/len(y_train)),3), round((traindata_dist[1]/len(y_train)),3)))\n",
    "print('Valiadity Data Class Distribution # Count :{}, 0/1 Ratio :{}, Class-0 % :{}, Class-1 % :{}'.format(validitydata_dist, round((validitydata_dist[0]/ validitydata_dist[1]),3), round((validitydata_dist[0]/len(y_valid)),3), round((validitydata_dist[1]/len(y_valid)),3)))\n",
    "print('Test Data Class Distribution      # Count :{}, 0/1 Ratio :{}, Class-0 % :{}, Class-1 % :{}'.format(testdata_dist, round((testdata_dist[0] / testdata_dist[1]),3), round((testdata_dist[0]/len(y_test)),3), round((testdata_dist[1]/len(y_test)),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, f1_score, accuracy_score\n",
    "\n",
    "def TestReport(model_name, y_true, y_pred):\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    f1_ = f1_score(y_true, y_pred,average='weighted')\n",
    "    acc_scr = accuracy_score(y_true, y_pred)\n",
    "    print('{} \\t |--> Precision : {} Recall : {} F1-Score : {} Accuracy-Score : {}'.format(model_name, round(precision,3), round(recall,3), round(f1_,3), round(acc_scr,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \t |--> Precision : 0.797 Recall : 0.796 F1-Score : 0.797 Accuracy-Score : 0.796\n",
      "DecisionTreeClassifier \t |--> Precision : 0.995 Recall : 0.995 F1-Score : 0.995 Accuracy-Score : 0.995\n",
      "RandomForestClassifier \t |--> Precision : 0.999 Recall : 0.999 F1-Score : 0.999 Accuracy-Score : 0.999\n",
      "KNeighborsClassifier \t |--> Precision : 0.918 Recall : 0.904 F1-Score : 0.902 Accuracy-Score : 0.904\n",
      "GaussianNB \t |--> Precision : 0.706 Recall : 0.707 F1-Score : 0.702 Accuracy-Score : 0.707\n",
      "VotingClassifier \t |--> Precision : 0.987 Recall : 0.987 F1-Score : 0.987 Accuracy-Score : 0.987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "kn_clf = KNeighborsClassifier()\n",
    "nb_clf = GaussianNB()\n",
    "vt_clf_model = VotingClassifier(estimators=[('lr',lr_clf),('dt',dt_clf),('rf',rf_clf),('kn',kn_clf),('nb',nb_clf)], voting='soft')\n",
    "\n",
    "\n",
    "for clf_model in (lr_clf, dt_clf, rf_clf, kn_clf, nb_clf, vt_clf_model):\n",
    "    clf_model.fit(x_train, y_train)\n",
    "    y_pred = clf_model.predict(x_valid)\n",
    "    TestReport(clf_model.__class__.__name__, y_valid, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_dataset.select_dtypes('object'):\n",
    "    print(col)\n",
    "    test_dataset[col] = category_colmap[col].transform(test_dataset[col])\n",
    "    \n",
    "x_test, y_test = test_dataset[x_features], test_dataset[y_predictor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246318 entries, 0 to 246317\n",
      "Data columns (total 26 columns):\n",
      "addr_state             246318 non-null int64\n",
      "annual_inc             246318 non-null float64\n",
      "issue_d                246318 non-null int64\n",
      "application_type       246318 non-null int64\n",
      "dti                    246318 non-null float64\n",
      "emp_length             246318 non-null int64\n",
      "emp_title              246318 non-null int64\n",
      "funded_amnt            246318 non-null float64\n",
      "funded_amnt_inv        246318 non-null float64\n",
      "grade                  246318 non-null int64\n",
      "home_ownership         246318 non-null int64\n",
      "id                     246318 non-null int64\n",
      "initial_list_status    246318 non-null int64\n",
      "loan_amnt              246318 non-null float64\n",
      "member_id              246318 non-null int64\n",
      "policy_code            246318 non-null float64\n",
      "pub_rec                246318 non-null float64\n",
      "purpose                246318 non-null int64\n",
      "sub_grade              246318 non-null int64\n",
      "term                   246318 non-null int64\n",
      "title                  246318 non-null int64\n",
      "total_acc              246318 non-null float64\n",
      "total_pymnt            246318 non-null float64\n",
      "zip_code               246318 non-null int64\n",
      "verification_status    246318 non-null int64\n",
      "default_ind            246318 non-null int64\n",
      "dtypes: float64(9), int64(17)\n",
      "memory usage: 48.9 MB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \t |--> Precision : 0.967 Recall : 0.854 F1-Score : 0.905 Accuracy-Score : 0.854\n",
      "DecisionTreeClassifier \t |--> Precision : 0.972 Recall : 0.516 F1-Score : 0.664 Accuracy-Score : 0.516\n",
      "RandomForestClassifier \t |--> Precision : 0.975 Recall : 0.594 F1-Score : 0.728 Accuracy-Score : 0.594\n",
      "KNeighborsClassifier \t |--> Precision : 0.965 Recall : 0.98 F1-Score : 0.972 Accuracy-Score : 0.98\n",
      "GaussianNB \t |--> Precision : 0.964 Recall : 0.98 F1-Score : 0.972 Accuracy-Score : 0.98\n",
      "VotingClassifier \t |--> Precision : 0.968 Recall : 0.958 F1-Score : 0.963 Accuracy-Score : 0.958\n"
     ]
    }
   ],
   "source": [
    "for clf_model in (lr_clf, dt_clf, rf_clf, kn_clf, nb_clf, vt_clf_model):\n",
    "    y_pred = clf_model.predict(x_test)\n",
    "    TestReport(clf_model.__class__.__name__, y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
